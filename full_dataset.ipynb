{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe called full_dataset wtih columns: Timestamp, ActivityCounts, Barometer, BloodPerfusion, BloodPulseWave, EnergyExpenditure, HR,HRV,RESP,Steps,SkinTemperature,SubjectID\n",
    "full_dataset = pd.DataFrame(columns=['Timestamp', 'ActivityCounts', 'Barometer', \n",
    "                                     'BloodPerfusion', 'BloodPulseWave', 'EnergyExpenditure', \n",
    "                                     'HR', 'HRV', 'RESP', 'Steps', 'SkinTemperature', \n",
    "                                     'SubjectID'])\n",
    "date_format = '%d.%m.%y %H:%M'\n",
    "dfs=[]\n",
    "num_rows = 0\n",
    "for i in range(1, 29):\n",
    "    file_path = 'data/raw/subjectID_' + str(i) + '.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "    # if there is an acitivity class column, drop it\n",
    "    if 'ActivityClass' in df.columns:\n",
    "        df = df.drop(['ActivityClass'], axis=1)\n",
    "    # if there is a galvanic skin response column, drop it\n",
    "    if 'GalvanicSkinResponse' in df.columns:\n",
    "        df = df.drop(['GalvanicSkinResponse'], axis=1)\n",
    "    # if there is a column called 'SkinTemperature.Value', rename it to 'SkinTemperature'\n",
    "    if 'SkinTemperature.Value' in df.columns:\n",
    "        df = df.rename(columns={'SkinTemperature.Value': 'SkinTemperature'})\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'], format=date_format)\n",
    "    # create a new data frame that contains the 10 minute average of each column\n",
    "    df = df.set_index('Timestamp')\n",
    "    df = df.resample('10T').mean()  # '10T' stands for 10 minutes\n",
    "    df = df.reset_index()\n",
    "    # create a new column for the subject ID\n",
    "    df['SubjectID'] = i\n",
    "    # add rows in df to full_dataset\n",
    "    dfs.append(df)\n",
    "\n",
    "\n",
    "full_dataset = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>ActivityCounts</th>\n",
       "      <th>Barometer</th>\n",
       "      <th>BloodPerfusion</th>\n",
       "      <th>BloodPulseWave</th>\n",
       "      <th>EnergyExpenditure</th>\n",
       "      <th>HR</th>\n",
       "      <th>HRV</th>\n",
       "      <th>RESP</th>\n",
       "      <th>Steps</th>\n",
       "      <th>SkinTemperature</th>\n",
       "      <th>SubjectID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-03-14 14:30:00</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>981.225000</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1004.848755</td>\n",
       "      <td>79.201816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.860000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-03-14 14:40:00</td>\n",
       "      <td>3.006536</td>\n",
       "      <td>981.166667</td>\n",
       "      <td>0.608000</td>\n",
       "      <td>1.604000</td>\n",
       "      <td>1002.522716</td>\n",
       "      <td>77.051356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.490989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.859444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-03-14 14:50:00</td>\n",
       "      <td>3.398693</td>\n",
       "      <td>981.211111</td>\n",
       "      <td>0.584167</td>\n",
       "      <td>1.938333</td>\n",
       "      <td>1154.805566</td>\n",
       "      <td>84.622675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.241810</td>\n",
       "      <td>7.888889</td>\n",
       "      <td>29.280556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-03-14 15:00:00</td>\n",
       "      <td>1.176471</td>\n",
       "      <td>981.010000</td>\n",
       "      <td>0.381000</td>\n",
       "      <td>2.132000</td>\n",
       "      <td>1701.043952</td>\n",
       "      <td>71.817909</td>\n",
       "      <td>45.770417</td>\n",
       "      <td>15.745870</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>32.827500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-03-14 15:10:00</td>\n",
       "      <td>9.568627</td>\n",
       "      <td>981.250000</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>2.356000</td>\n",
       "      <td>4240.149158</td>\n",
       "      <td>95.510233</td>\n",
       "      <td>45.626667</td>\n",
       "      <td>18.235506</td>\n",
       "      <td>15.200000</td>\n",
       "      <td>34.298500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135571</th>\n",
       "      <td>2018-08-16 07:10:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135572</th>\n",
       "      <td>2018-08-16 07:20:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135573</th>\n",
       "      <td>2018-08-16 07:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135574</th>\n",
       "      <td>2018-08-16 07:40:00</td>\n",
       "      <td>0.784314</td>\n",
       "      <td>988.100000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>2.380000</td>\n",
       "      <td>1027.824555</td>\n",
       "      <td>58.299174</td>\n",
       "      <td>83.916667</td>\n",
       "      <td>14.663512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.293333</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135575</th>\n",
       "      <td>2018-08-16 07:50:00</td>\n",
       "      <td>1.078431</td>\n",
       "      <td>988.287500</td>\n",
       "      <td>0.361250</td>\n",
       "      <td>2.525000</td>\n",
       "      <td>1020.430134</td>\n",
       "      <td>61.573231</td>\n",
       "      <td>74.019945</td>\n",
       "      <td>15.033386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.541250</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135576 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Timestamp  ActivityCounts   Barometer  BloodPerfusion  \\\n",
       "0      2019-03-14 14:30:00        0.980392  981.225000        0.087500   \n",
       "1      2019-03-14 14:40:00        3.006536  981.166667        0.608000   \n",
       "2      2019-03-14 14:50:00        3.398693  981.211111        0.584167   \n",
       "3      2019-03-14 15:00:00        1.176471  981.010000        0.381000   \n",
       "4      2019-03-14 15:10:00        9.568627  981.250000        0.345000   \n",
       "...                    ...             ...         ...             ...   \n",
       "135571 2018-08-16 07:10:00             NaN         NaN             NaN   \n",
       "135572 2018-08-16 07:20:00             NaN         NaN             NaN   \n",
       "135573 2018-08-16 07:30:00             NaN         NaN             NaN   \n",
       "135574 2018-08-16 07:40:00        0.784314  988.100000        0.370000   \n",
       "135575 2018-08-16 07:50:00        1.078431  988.287500        0.361250   \n",
       "\n",
       "        BloodPulseWave  EnergyExpenditure         HR        HRV       RESP  \\\n",
       "0             0.950000        1004.848755  79.201816        NaN        NaN   \n",
       "1             1.604000        1002.522716  77.051356        NaN  13.490989   \n",
       "2             1.938333        1154.805566  84.622675        NaN  19.241810   \n",
       "3             2.132000        1701.043952  71.817909  45.770417  15.745870   \n",
       "4             2.356000        4240.149158  95.510233  45.626667  18.235506   \n",
       "...                ...                ...        ...        ...        ...   \n",
       "135571             NaN                NaN        NaN        NaN        NaN   \n",
       "135572             NaN                NaN        NaN        NaN        NaN   \n",
       "135573             NaN                NaN        NaN        NaN        NaN   \n",
       "135574        2.380000        1027.824555  58.299174  83.916667  14.663512   \n",
       "135575        2.525000        1020.430134  61.573231  74.019945  15.033386   \n",
       "\n",
       "            Steps  SkinTemperature  SubjectID  \n",
       "0        0.000000        28.860000          1  \n",
       "1        0.000000        30.859444          1  \n",
       "2        7.888889        29.280556          1  \n",
       "3        9.400000        32.827500          1  \n",
       "4       15.200000        34.298500          1  \n",
       "...           ...              ...        ...  \n",
       "135571        NaN              NaN         28  \n",
       "135572        NaN              NaN         28  \n",
       "135573        NaN              NaN         28  \n",
       "135574   0.000000        34.293333         28  \n",
       "135575   0.000000        34.541250         28  \n",
       "\n",
       "[135576 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SubjectID</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>Timezone</th>\n",
       "      <th>question</th>\n",
       "      <th>PROanswer_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-14 20:01:00</td>\n",
       "      <td>UTC</td>\n",
       "      <td>VAS</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-14 20:01:00</td>\n",
       "      <td>UTC</td>\n",
       "      <td>RelP</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-14 20:01:00</td>\n",
       "      <td>UTC</td>\n",
       "      <td>PhF</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-14 20:01:00</td>\n",
       "      <td>UTC</td>\n",
       "      <td>MF</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-03-15 20:01:00</td>\n",
       "      <td>UTC</td>\n",
       "      <td>VAS</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>28</td>\n",
       "      <td>2018-08-16 00:51:00</td>\n",
       "      <td>CEST</td>\n",
       "      <td>MF</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076</th>\n",
       "      <td>28</td>\n",
       "      <td>2018-08-16 00:52:00</td>\n",
       "      <td>CEST</td>\n",
       "      <td>VAS</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>28</td>\n",
       "      <td>2018-08-16 00:52:00</td>\n",
       "      <td>CEST</td>\n",
       "      <td>RelP</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>28</td>\n",
       "      <td>2018-08-16 00:52:00</td>\n",
       "      <td>CEST</td>\n",
       "      <td>PhF</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079</th>\n",
       "      <td>28</td>\n",
       "      <td>2018-08-16 00:52:00</td>\n",
       "      <td>CEST</td>\n",
       "      <td>MF</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2080 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SubjectID            DateTime Timezone question  PROanswer_value\n",
       "0             1 2019-03-14 20:01:00      UTC      VAS              2.0\n",
       "1             1 2019-03-14 20:01:00      UTC     RelP             -1.0\n",
       "2             1 2019-03-14 20:01:00      UTC      PhF              0.0\n",
       "3             1 2019-03-14 20:01:00      UTC       MF              1.0\n",
       "4             1 2019-03-15 20:01:00      UTC      VAS              2.0\n",
       "...         ...                 ...      ...      ...              ...\n",
       "2075         28 2018-08-16 00:51:00     CEST       MF              1.0\n",
       "2076         28 2018-08-16 00:52:00     CEST      VAS              4.0\n",
       "2077         28 2018-08-16 00:52:00     CEST     RelP              1.0\n",
       "2078         28 2018-08-16 00:52:00     CEST      PhF              0.0\n",
       "2079         28 2018-08-16 00:52:00     CEST       MF              1.0\n",
       "\n",
       "[2080 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fatiguePROs = pd.read_csv('data/fatiguePROs_processed.csv')\n",
    "\n",
    "fatiguePROs.reset_index(drop=True, inplace=True)\n",
    "# convert the Timestamp column to datetime type\n",
    "fatiguePROs['DateTime'] = pd.to_datetime(fatiguePROs['DateTime'], format=date_format)\n",
    "# find all timestamp that have missing values in the proanswers column\n",
    "missing_proanswers = fatiguePROs[fatiguePROs['PROanswer_value'].isnull()].DateTime.unique()\n",
    "# drop all rows that have the above timestamps\n",
    "fatiguePROs = fatiguePROs[~fatiguePROs['DateTime'].isin(missing_proanswers)]\n",
    "fatiguePROs.reset_index(drop=True, inplace=True)\n",
    "fatiguePROs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments_fulldataset = []\n",
    "segments_subjectIDs = []\n",
    "PROlabels_PhF = []\n",
    "PROlabels_MF = []\n",
    "PROlabels_VAS = []\n",
    "PROlabels_RelP = []\n",
    "\n",
    "for i in range(1, 29):\n",
    "    # subset full_dataset to get data for subject i\n",
    "    subject_data = full_dataset[full_dataset['SubjectID'] == i]\n",
    "    # subset fatiguePROs to get data for subject i\n",
    "    subject_labels = fatiguePROs[fatiguePROs['SubjectID'] == i]\n",
    "    unique_date_time = subject_labels['DateTime'].unique()\n",
    "    \n",
    "    for j in range(len(unique_date_time)):\n",
    "        #  find the date of unique_date_time[i]\n",
    "\n",
    "        start_date_time = max(unique_date_time[j] - pd.Timedelta(days=5), subject_data['Timestamp'].min())\n",
    "        end_date_time = unique_date_time[j]\n",
    "        \n",
    "        segment = subject_data[(subject_data['Timestamp'] > start_date_time) & (subject_data['Timestamp'] <= end_date_time)]  \n",
    "        # remove the timestamp column\n",
    "        segment = segment.drop(columns=['Timestamp'])\n",
    "        # if >=80% of the values in the segment are not NaN or None, append the segment to a new data frame\n",
    "        if segment.size > 0 and segment.notnull().sum().sum() / segment.size >= 0.8:\n",
    "            segment = segment.to_numpy()\n",
    "           \n",
    "            segments_fulldataset.append(segment)\n",
    "            segments_subjectIDs.append(i)\n",
    "            # find the PROlabel that corresponds to the DateTime, append it to PROlabels\n",
    "            PROlabel = subject_labels[subject_labels['DateTime'] == end_date_time]\n",
    "            PROlabels_PhF.append(PROlabel[PROlabel['question'] == 'PhF'].PROanswer_value.values[0])\n",
    "            PROlabels_MF.append(PROlabel[PROlabel['question'] == 'MF'].PROanswer_value.values[0])\n",
    "            PROlabels_VAS.append(PROlabel[PROlabel['question'] == 'VAS'].PROanswer_value.values[0])\n",
    "            PROlabels_RelP.append(PROlabel[PROlabel['question'] == 'RelP'].PROanswer_value.values[0])\n",
    "len(segments_fulldataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/jenny/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.W_q = nn.Linear(hidden_size, hidden_size)\n",
    "        self.W_k = nn.Linear(hidden_size, hidden_size)\n",
    "        self.W_v = nn.Linear(hidden_size, hidden_size)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        query = self.W_q(x)\n",
    "        key = self.W_k(x)\n",
    "        value = self.W_v(x)\n",
    "\n",
    "        attention_weights = torch.matmul(query, key.transpose(-2, -1))\n",
    "        attention_weights = attention_weights / torch.sqrt(torch.tensor(x.size(-1), dtype=torch.float32))\n",
    "\n",
    "        attention_weights = self.softmax(attention_weights)\n",
    "        out = torch.matmul(attention_weights, value)\n",
    "\n",
    "        return out\n",
    "\n",
    "class LSTMWithSelfAttention(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers):\n",
    "        super(LSTMWithSelfAttention, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.self_attention = SelfAttention(hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size*2, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "\n",
    "        # Apply self-attention\n",
    "        attention_out = self.self_attention(out)\n",
    "\n",
    "        # Concatenate LSTM output and attention output\n",
    "        out = torch.cat((out[:, -1, :], attention_out[:, -1, :]), dim=-1)\n",
    "\n",
    "        # Fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhF\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "# repeat the above steps for PhF, MF, and RelP, do it in a loop\n",
    "PROlabels = [PROlabels_PhF, PROlabels_MF, PROlabels_VAS, PROlabels_RelP]\n",
    "PROlabels_name = ['PhF', 'MF', 'VAS', 'RelP']\n",
    "\n",
    "lst_outputs = []\n",
    "lst_targets = []\n",
    "\n",
    "for i in range(len(PROlabels)):\n",
    "    np.random.seed(0)\n",
    "    print(PROlabels_name[i])\n",
    "    # Assuming your data is stored in 'data' and labels in 'labels'\n",
    "    X_train, X_test, y_train, y_test = train_test_split(segments_fulldataset, PROlabels[i], test_size=0.2, random_state=42)\n",
    "\n",
    "    \n",
    "    # Pad sequences with zeros\n",
    "    X_train = pad_sequence([torch.tensor(seq, dtype=torch.float32) for seq in X_train], batch_first=True, padding_value=float('nan'))\n",
    "    X_test = pad_sequence([torch.tensor(seq, dtype=torch.float32) for seq in X_test], batch_first=True, padding_value=float('nan'))\n",
    "    y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "    X_train = torch.nan_to_num(X_train)\n",
    "    X_test = torch.nan_to_num(X_test)\n",
    "\n",
    "    X_train.shape, y_train.shape, X_test.shape, y_test.shape\n",
    "    # Instantiate the model\n",
    "    input_size = 10  # Adjust according to your data\n",
    "    hidden_size = 128\n",
    "    output_size = 1  # Assuming regression task\n",
    "    num_layers = 4\n",
    "    consistency_attention_size = 4\n",
    "    \n",
    "    model = LSTMWithSelfAttention(input_size, hidden_size, output_size, num_layers)\n",
    "    \n",
    "    # model = LSTMWithAttention(input_size, hidden_size, output_size, num_layers, consistency_attention_size)\n",
    "\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Training the model\n",
    "    num_epochs = 30\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs.squeeze(), y_train)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "        # Evaluate the model on the test set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test)\n",
    "\n",
    "        lst_outputs.append(test_outputs)\n",
    "        lst_targets.append(y_test)\n",
    "        \n",
    "        test_loss = criterion(test_outputs.squeeze(), y_test)\n",
    "        print(f'Test Loss: {test_loss.item():.4f}')\n",
    "\n",
    "        y_test_np = y_test.numpy()\n",
    "        test_outputs_np = test_outputs.numpy()\n",
    "\n",
    "        # Create a scatter plot\n",
    "        # make x and y axis have the same scale\n",
    "        if PROlabels_name[i] == 'VAS':\n",
    "            plt.xlim(0.5, 10.5)\n",
    "            plt.ylim(0.5, 10.5)\n",
    "        elif PROlabels_name[i] == 'RelP':\n",
    "            plt.xlim(-1.25, 1.25)\n",
    "            plt.ylim(-1.25, 1.25)\n",
    "        else:\n",
    "            plt.xlim(-0.5, 4.5)\n",
    "            plt.ylim(-0.5, 4.5)\n",
    "\n",
    "        plt.gca().set_aspect('equal', adjustable='box')\n",
    "        plt.scatter(y_test_np, test_outputs_np, alpha=0.5)\n",
    "        plt.title(PROlabels_name[i], y=-0.2)\n",
    "        plt.xlabel('Groud Truth')\n",
    "        plt.ylabel('Predictions')\n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "   \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
