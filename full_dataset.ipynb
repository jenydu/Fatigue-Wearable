{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = pd.DataFrame(columns=['Timestamp', 'ActivityCounts', 'Barometer', \n",
    "                                     'BloodPerfusion', 'BloodPulseWave', 'EnergyExpenditure', \n",
    "                                     'HR', 'HRV', 'RESP', 'Steps', 'SkinTemperature', \n",
    "                                     'SubjectID'])\n",
    "date_format = '%d.%m.%y %H:%M'\n",
    "dfs=[]\n",
    "num_rows = 0\n",
    "for i in range(1, 29):\n",
    "    file_path = 'data/raw/subjectID_' + str(i) + '.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    if 'ActivityClass' in df.columns:\n",
    "        df = df.drop(['ActivityClass'], axis=1)\n",
    "    if 'GalvanicSkinResponse' in df.columns:\n",
    "        df = df.drop(['GalvanicSkinResponse'], axis=1)\n",
    "\n",
    "    if 'SkinTemperature.Value' in df.columns:\n",
    "        df = df.rename(columns={'SkinTemperature.Value': 'SkinTemperature'})\n",
    "    \n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'], format=date_format)\n",
    "    df = df.set_index('Timestamp')\n",
    "    \n",
    "    # resample to be the mean of hour\n",
    "    df = df.resample('H').mean()\n",
    "    df = df.reset_index()\n",
    "\n",
    "    df['SubjectID'] = i\n",
    "    dfs.append(df)\n",
    "\n",
    "full_dataset = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fatiguePROs = pd.read_csv('data/fatiguePROs_processed.csv')\n",
    "\n",
    "fatiguePROs.reset_index(drop=True, inplace=True)\n",
    "# convert the Timestamp column to datetime type\n",
    "fatiguePROs['DateTime'] = pd.to_datetime(fatiguePROs['DateTime'], format=date_format)\n",
    "# find all timestamp that have missing values in the proanswers column\n",
    "missing_proanswers = fatiguePROs[fatiguePROs['PROanswer_value'].isnull()].DateTime.unique()\n",
    "# drop all rows that have the above timestamps\n",
    "fatiguePROs = fatiguePROs[~fatiguePROs['DateTime'].isin(missing_proanswers)]\n",
    "fatiguePROs.reset_index(drop=True, inplace=True)\n",
    "fatiguePROs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract 5 day segments from full_dataset\n",
    "segments_fulldataset = []\n",
    "segments_subjectIDs = []\n",
    "PROlabels_PhF = []\n",
    "PROlabels_MF = []\n",
    "PROlabels_VAS = []\n",
    "PROlabels_RelP = []\n",
    "\n",
    "for i in range(1, 29):\n",
    "    subject_data = full_dataset[full_dataset['SubjectID'] == i]\n",
    "    subject_labels = fatiguePROs[fatiguePROs['SubjectID'] == i]\n",
    "    unique_date_time = subject_labels['DateTime'].unique()\n",
    "    \n",
    "    for j in range(len(unique_date_time)):\n",
    "        start_date_time = max(unique_date_time[j] - pd.Timedelta(days=5), subject_data['Timestamp'].min())\n",
    "        end_date_time = unique_date_time[j]\n",
    "        \n",
    "        segment = subject_data[(subject_data['Timestamp'] > start_date_time) & (subject_data['Timestamp'] <= end_date_time)]  \n",
    "        segment = segment.drop(columns=['Timestamp'])\n",
    "        segment = segment.drop(columns=['SubjectID'])\n",
    "\n",
    "        segment = (segment - segment.mean()) / segment.std()\n",
    "\n",
    "        # if >=80% of the values in the segment are not NaN or None, append the segment to a new data frame\n",
    "        if segment.size > 0 and segment.notnull().sum().sum() / segment.size >= 0.8 and segment.shape[0] == 120:\n",
    "            segment = segment.to_numpy()\n",
    "            segments_fulldataset.append(segment)\n",
    "            segments_subjectIDs.append(i)\n",
    "\n",
    "            # find the PROlabel that corresponds to the DateTime, append it to PROlabels\n",
    "            PROlabel = subject_labels[subject_labels['DateTime'] == end_date_time]\n",
    "            PROlabels_PhF.append(PROlabel[PROlabel['question'] == 'PhF'].PROanswer_value.values[0])\n",
    "            PROlabels_MF.append(PROlabel[PROlabel['question'] == 'MF'].PROanswer_value.values[0])\n",
    "            PROlabels_VAS.append(PROlabel[PROlabel['question'] == 'VAS'].PROanswer_value.values[0])\n",
    "            PROlabels_RelP.append(PROlabel[PROlabel['question'] == 'RelP'].PROanswer_value.values[0])\n",
    "\n",
    "len(segments_fulldataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of occurrences of each subject ID\n",
    "_, counts = np.unique(segments_subjectIDs, return_counts=True)\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_groups(nums, num_groups):\n",
    "    nums_with_index = list(enumerate(nums))\n",
    "    nums_with_index.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    group_assignments = [0] * len(nums)\n",
    "    group_sums = [0] * num_groups\n",
    "\n",
    "    for index, num in nums_with_index:\n",
    "        min_sum_index = min(range(num_groups), key=lambda i: group_sums[i])\n",
    "        group_sums[min_sum_index] += num\n",
    "        group_assignments[index] = min_sum_index\n",
    "\n",
    "    return group_assignments, group_sums\n",
    "\n",
    "num_groups = 5\n",
    "\n",
    "group_assignments, group_sums = split_into_groups(counts, num_groups)\n",
    "print(group_assignments)\n",
    "\n",
    "for i, group_sum in enumerate(group_sums):\n",
    "    print(f\"Group {i + 1} sum: {group_sum}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_group_assignemnt = []\n",
    "\n",
    "for group, count in zip(group_assignments, counts):\n",
    "    full_group_assignemnt.extend([group] * count)\n",
    "\n",
    "print(full_group_assignemnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class AttentionLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(AttentionLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        attention_weights = self.softmax(lstm_out)\n",
    "        context_vector = torch.sum(attention_weights * lstm_out, dim=1)\n",
    "        output = self.fc(context_vector)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROlabels = [PROlabels_PhF, PROlabels_MF, PROlabels_VAS, PROlabels_RelP]\n",
    "PROlabels_name = ['PhF', 'MF', 'VAS', 'RelP']\n",
    "\n",
    "lst_outputs = []\n",
    "lst_targets = []\n",
    "\n",
    "for i in range(len(PROlabels)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(segments_fulldataset, PROlabels[i], test_size=0.2, random_state=42)\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "    X_train_tensor = torch.nan_to_num(X_train_tensor, nan=-10000.0)\n",
    "    X_test_tensor = torch.nan_to_num(X_test_tensor, nan=-10000.0)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    batch_size = 64\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Initialize the model, loss function, and optimizer\n",
    "    input_size = 10 \n",
    "    hidden_size = 64 \n",
    "    output_size = 1 \n",
    "    model = AttentionLSTM(input_size, hidden_size, output_size)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the model\n",
    "    num_epochs = 30\n",
    "    train_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "        train_losses.append(avg_epoch_loss)\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_epoch_loss:.4f}')\n",
    "    \n",
    "    # torch.save(model, f'models/LSTMWithSelfAttention_{PROlabels_name[i]}.pth')\n",
    "    \n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = []\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            test_outputs.extend(outputs.squeeze().tolist())\n",
    "\n",
    "    test_outputs = np.array(test_outputs)\n",
    "    y_test = np.array(y_test)\n",
    "    lst_outputs.append(test_outputs)\n",
    "    lst_targets.append(y_test)\n",
    "\n",
    "    if PROlabels_name[i] == 'VAS':\n",
    "        plt.xlim(0.5, 10.5)\n",
    "        plt.ylim(0.5, 10.5)\n",
    "    elif PROlabels_name[i] == 'RelP':\n",
    "        plt.xlim(-1.25, 1.25)\n",
    "        plt.ylim(-1.25, 1.25)\n",
    "    else:\n",
    "        plt.xlim(-0.5, 4.5)\n",
    "        plt.ylim(-0.5, 4.5)\n",
    "\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    # Plot scatter plot\n",
    "    plt.scatter(y_test, test_outputs, alpha=0.5)\n",
    "    plt.title(PROlabels_name[i], y=-0.2)\n",
    "    plt.xlabel('Groud Truth')\n",
    "    plt.ylabel('Predictions')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "    # Evaluate the performance \n",
    "    mse = mean_squared_error(y_test, test_outputs)\n",
    "    print(f'Mean Squared Error on Test Data: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data-based kfold CV\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "PROlabels = [PROlabels_PhF, PROlabels_MF, PROlabels_VAS, PROlabels_RelP]\n",
    "PROlabels_name = ['PhF', 'MF', 'VAS', 'RelP']\n",
    "\n",
    "lst_outputs = []\n",
    "lst_targets = []\n",
    "\n",
    "# Number of folds for cross-validation\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "mse_values = {label: [] for label in PROlabels_name}\n",
    "\n",
    "for i, label in enumerate(PROlabels_name):\n",
    "    X = np.array(segments_fulldataset)\n",
    "    y = np.array(PROlabels[i])\n",
    "\n",
    "    fold = 1\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        print(f'Fold {fold}/{num_folds}')\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Convert data to PyTorch tensors\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "        y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "        X_train_tensor = torch.nan_to_num(X_train_tensor, nan=-10000.0)\n",
    "        X_test_tensor = torch.nan_to_num(X_test_tensor, nan=-10000.0)\n",
    "        # Create DataLoader\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "        batch_size = 64\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Initialize the model, loss function, and optimizer\n",
    "        input_size = 10 \n",
    "        hidden_size = 64 \n",
    "        output_size = 1 \n",
    "        model = AttentionLSTM(input_size, hidden_size, output_size)\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        # Train the model\n",
    "        num_epochs = 30\n",
    "        train_losses = []\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            epoch_loss = 0.0\n",
    "            for inputs, labels in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs.squeeze(), labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "            avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "            train_losses.append(avg_epoch_loss)\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_epoch_loss:.4f}')\n",
    "        \n",
    "        # torch.save(model, f'models/LSTMWithSelfAttention_{PROlabels_name[i]}_binary.pth')\n",
    "        \n",
    "        # Evaluate the model\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_outputs = []\n",
    "            for inputs, labels in test_loader:\n",
    "                outputs = model(inputs).squeeze()\n",
    "\n",
    "                test_outputs.extend(outputs.squeeze().tolist())\n",
    "  \n",
    "        mse = mean_squared_error(y_test, test_outputs)\n",
    "        mse_values[label].append(mse)\n",
    "        print(f'Mean Squared Error on Test Data (Fold {fold}): {mse}')\n",
    "\n",
    "        fold += 1\n",
    "\n",
    "# Calculate average and standard deviation for each PROlabel\n",
    "for label in PROlabels_name:\n",
    "    mse_array = np.array(mse_values[label])\n",
    "    avg_mse = np.mean(mse_array)\n",
    "    sd_mse = np.std(mse_array)\n",
    "    print(f'PROlabel: {label}, Average MSE: {avg_mse}, SD MSE: {sd_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject-based kfold CV\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "PROlabels = [PROlabels_PhF, PROlabels_MF, PROlabels_VAS, PROlabels_RelP]\n",
    "PROlabels_name = ['PhF', 'MF', 'VAS', 'RelP']\n",
    "\n",
    "lst_outputs = []\n",
    "lst_targets = []\n",
    "# Number of folds for cross-validation\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "mse_values = {label: [] for label in PROlabels_name}\n",
    "\n",
    "new_array = full_group_assignemnt\n",
    "for i, label in enumerate(PROlabels_name):\n",
    "    X = np.array(segments_fulldataset)\n",
    "    y = np.array(PROlabels[i])\n",
    "\n",
    "    fold = 1\n",
    "    for group in np.unique(new_array):\n",
    "        print(f'Fold {fold}/{num_folds}')\n",
    "\n",
    "        group_indices = np.where(new_array == group)[0]\n",
    "\n",
    "        # Split data based on group indices\n",
    "        X_test = X[group_indices]\n",
    "        y_test = y[group_indices]\n",
    "\n",
    "        train_indices = np.setdiff1d(np.arange(len(X)), group_indices)\n",
    "        X_train = X[train_indices]\n",
    "        y_train = y[train_indices]\n",
    "\n",
    "        # Convert data to PyTorch tensors\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "        y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "        X_train_tensor = torch.nan_to_num(X_train_tensor, nan=-10000.0)\n",
    "        X_test_tensor = torch.nan_to_num(X_test_tensor, nan=-10000.0)\n",
    "        # Create DataLoader\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "        batch_size = 64\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Initialize the model, loss function, and optimizer\n",
    "        input_size = 10  \n",
    "        hidden_size = 64  \n",
    "        output_size = 1  \n",
    "        model = AttentionLSTM(input_size, hidden_size, output_size)\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        # Train the model\n",
    "        num_epochs = 30\n",
    "        train_losses = []\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            epoch_loss = 0.0\n",
    "            for inputs, labels in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs.squeeze(), labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "            avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "            train_losses.append(avg_epoch_loss)\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_epoch_loss:.4f}')\n",
    "        \n",
    "        # torch.save(model, f'models/LSTMWithSelfAttention_{PROlabels_name[i]}_binary.pth')\n",
    "        \n",
    "        # Evaluate the model\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_outputs = []\n",
    "            for inputs, labels in test_loader:\n",
    "                outputs = model(inputs).squeeze()\n",
    "                # print(outputs)\n",
    "                # if output is a float, convert to a tensor of size 1\n",
    "                if outputs.dim() == 0:\n",
    "                    test_outputs.append(outputs)\n",
    "                else:\n",
    "                    test_outputs.extend(outputs.tolist())\n",
    "                \n",
    "        mse = mean_squared_error(y_test, test_outputs)\n",
    "        mse_values[label].append(mse)\n",
    "        print(f'Mean Squared Error on Test Data (Fold {fold}): {mse}')\n",
    "\n",
    "        fold += 1\n",
    "\n",
    "# Calculate average and standard deviation for each PROlabel\n",
    "for label in PROlabels_name:\n",
    "    mse_array = np.array(mse_values[label])\n",
    "    avg_mse = np.mean(mse_array)\n",
    "    sd_mse = np.std(mse_array)\n",
    "    print(f'PROlabel: {label}, Average MSE: {avg_mse}, SD MSE: {sd_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 FOLD\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "PROlabels = [PROlabels_PhF, PROlabels_MF, PROlabels_VAS, PROlabels_RelP]\n",
    "PROlabels_name = ['PhF', 'MF', 'VAS', 'RelP']\n",
    "\n",
    "lst_outputs = []\n",
    "lst_targets = []\n",
    "# Number of folds for cross-validation\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "mse_values = {label: [] for label in PROlabels_name}\n",
    "\n",
    "new_array = full_group_assignemnt\n",
    "for i, label in enumerate(PROlabels_name):\n",
    "    X = np.array(segments_fulldataset)\n",
    "    y = np.array(PROlabels[i])\n",
    "\n",
    "    fold = 1\n",
    "    for group in np.unique(new_array)[2:3]:\n",
    "        print(f'Fold {fold}/{num_folds}')\n",
    "\n",
    "        group_indices = np.where(new_array == group)[0]\n",
    "\n",
    "        # Split data based on group indices\n",
    "        X_test = X[group_indices]\n",
    "        y_test = y[group_indices]\n",
    "\n",
    "        train_indices = np.setdiff1d(np.arange(len(X)), group_indices)\n",
    "        X_train = X[train_indices]\n",
    "        y_train = y[train_indices]\n",
    "\n",
    "        # Convert data to PyTorch tensors\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "        y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "        X_train_tensor = torch.nan_to_num(X_train_tensor, nan=-10000.0)\n",
    "        X_test_tensor = torch.nan_to_num(X_test_tensor, nan=-10000.0)\n",
    "        # Create DataLoader\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "        batch_size = 64\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Initialize the model, loss function, and optimizer\n",
    "        input_size = 10  \n",
    "        hidden_size = 64\n",
    "        output_size = 1  \n",
    "        model = AttentionLSTM(input_size, hidden_size, output_size)\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        # Train the model\n",
    "        num_epochs = 30\n",
    "        train_losses = []\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            epoch_loss = 0.0\n",
    "            for inputs, labels in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs.squeeze(), labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "            avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "            train_losses.append(avg_epoch_loss)\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_epoch_loss:.4f}')\n",
    "        \n",
    "        # torch.save(model, f'models/LSTMWithSelfAttention_{PROlabels_name[i]}_binary.pth')\n",
    "        \n",
    "        # Evaluate the model\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_outputs = []\n",
    "            for inputs, labels in test_loader:\n",
    "                outputs = model(inputs).squeeze()\n",
    "                # print(outputs)\n",
    "                # if output is a float, convert to a tensor of size 1\n",
    "                if outputs.dim() == 0:\n",
    "                    test_outputs.append(outputs)\n",
    "                else:\n",
    "                    test_outputs.extend(outputs.tolist())\n",
    "            \n",
    "        mse = mean_squared_error(y_test, test_outputs)\n",
    "        mse_values[label].append(mse)\n",
    "        test_outputs = np.array(test_outputs)\n",
    "        y_test = np.array(y_test)\n",
    "        lst_outputs.append(test_outputs)\n",
    "        lst_targets.append(y_test)\n",
    "        print(f'Mean Squared Error on Test Data (Fold {fold}): {mse}')\n",
    "\n",
    "        fold += 1\n",
    "\n",
    "# Calculate average and standard deviation for each PROlabel\n",
    "for label in PROlabels_name:\n",
    "    mse_array = np.array(mse_values[label])\n",
    "    avg_mse = np.mean(mse_array)\n",
    "    sd_mse = np.std(mse_array)\n",
    "    print(f'PROlabel: {label}, Average MSE: {avg_mse}, SD MSE: {sd_mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "num_plots = len(lst_outputs)\n",
    "\n",
    "# Create a 2x2 subplot layout\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10, 10))\n",
    "\n",
    "for i in range(num_plots):\n",
    "    row = i // 2\n",
    "    col = i % 2\n",
    "    ax = axes[row, col]\n",
    "    # print(len(lst_outputs_adjusted[i]), len(lst_targets[i]))\n",
    "    ax.scatter(lst_targets[i], lst_outputs[i], alpha=0.3)\n",
    "    m, b = np.polyfit(lst_targets[i], lst_outputs[i], 1)\n",
    "    ax.annotate(f'r={np.corrcoef(lst_targets[i], lst_outputs[i])[0,1]:.2f}', xy=(0.05, 0.9), xycoords='axes fraction')\n",
    "    ax.annotate(f'p={pearsonr(lst_targets[i], lst_outputs[i])[1]:.4f}', xy=(0.05, 0.85), xycoords='axes fraction')\n",
    "    ax.plot(lst_targets[i], m*lst_targets[i] + b, color='black', linewidth=1, alpha=0.6)\n",
    "    \n",
    "    if PROlabels_name[i] == 'VAS':\n",
    "        ax.set_xlim(0.5, 10.5)\n",
    "        ax.set_ylim(0.5, 10.5)\n",
    "    elif PROlabels_name[i] == 'RelP':\n",
    "        ax.set_xlim(-1.25, 1.25)\n",
    "        ax.set_ylim(-1.25, 1.25)\n",
    "    else:\n",
    "        ax.set_xlim(-0.5, 4.5)\n",
    "        ax.set_ylim(-0.5, 4.5)\n",
    "    ax.set_xlabel('Groud Truth')\n",
    "    ax.set_ylabel('Predictions')\n",
    "\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    ax.set_title(f'({chr(97 + i)}) {PROlabels_name[i]}', fontsize=12, fontweight='bold', loc='left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarized_predictions = []\n",
    "binarized_targets = []\n",
    "for i in range(len(lst_outputs)-1):\n",
    "    outputs = lst_outputs[i]\n",
    "    if i < 2:\n",
    "        binarized_predictions.append(np.where(np.round(outputs) >= 1 , 1, 0))\n",
    "        binarized_targets.append(np.where(np.round(lst_targets[i]) >= 1 , 1, 0))\n",
    "    else:\n",
    "        binarized_predictions.append(np.where(np.round(outputs) >= 5 , 1, 0))\n",
    "        binarized_targets.append(np.where(np.round(lst_targets[i]) >= 5 , 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the accuracy of the predictions\n",
    "from sklearn.metrics import accuracy_score\n",
    "for i in range(len(binarized_predictions)):\n",
    "    print(PROlabels_name[i])\n",
    "    print(accuracy_score(binarized_targets[i], binarized_predictions[i]))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save lst_outputs_adjusted, lst_outputs and lst_targets to csv files\n",
    "# import csv\n",
    "# with open('data/lst_outputs.csv', 'w') as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     writer.writerows(lst_outputs)\n",
    "# with open('data/lst_targets.csv', 'w') as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     writer.writerows(lst_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train model using binary labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class AttentionLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(AttentionLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        attention_weights = self.softmax(lstm_out)\n",
    "        context_vector = torch.sum(attention_weights * lstm_out, dim=1)\n",
    "        output = self.fc(context_vector)\n",
    "        # output = self.sigmoid(self.fc(context_vector))\n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "PROlabels = [PROlabels_PhF, PROlabels_MF, PROlabels_VAS, PROlabels_RelP]\n",
    "# PROlabels_name = ['PhF', 'MF', 'VAS', 'RelP']\n",
    "\n",
    "PROlabels = [np.where(np.array(PROlabels_PhF) >= 1 , 1, 0),\n",
    "                    np.where(np.array(PROlabels_MF) >= 1 , 1, 0),\n",
    "                    np.where(np.array(PROlabels_VAS) >= 5 , 1, 0)]\n",
    "\n",
    "PROlabels_name = ['PhF', 'MF', 'VAS']\n",
    "\n",
    "lst_outputs = []\n",
    "lst_targets = []\n",
    "\n",
    "for i in range(len(PROlabels)):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(segments_fulldataset, PROlabels[i], test_size=0.2, random_state=42)\n",
    "    # Convert data to PyTorch tensors\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "    X_train_tensor = torch.nan_to_num(X_train_tensor, nan=-10000.0)\n",
    "    X_test_tensor = torch.nan_to_num(X_test_tensor, nan=-10000.0)\n",
    "    # Create DataLoader\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "    batch_size = 64\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Initialize the model, loss function, and optimizer\n",
    "    input_size = 10 \n",
    "    hidden_size = 64  \n",
    "    output_size = 1  \n",
    "    model = AttentionLSTM(input_size, hidden_size, output_size)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the model\n",
    "    num_epochs = 30\n",
    "    train_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "        train_losses.append(avg_epoch_loss)\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_epoch_loss:.4f}')\n",
    "    \n",
    "    torch.save(model, f'models/LSTMWithSelfAttention_{PROlabels_name[i]}_binary.pth')\n",
    "    \n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = []\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs).squeeze()\n",
    "            outputs = np.where(outputs >= 0.5, 1, 0)\n",
    "            test_outputs.extend(outputs.squeeze().tolist())\n",
    "\n",
    "        # Compute evaluation metrics\n",
    "        accuracy = accuracy_score(y_test, test_outputs)\n",
    "        sensitivity = recall_score(y_test, test_outputs, average='weighted')\n",
    "        f1 = f1_score(y_test, test_outputs, average='weighted')\n",
    "        precision = precision_score(y_test, test_outputs, average='weighted', zero_division=1)\n",
    "        recall = recall_score(y_test, test_outputs, average='weighted')\n",
    "        print(f'Test Accuracy: {accuracy:.4f}'\n",
    "              f'\\nTest Precision: {precision:.4f}'\n",
    "              f'\\nTest Recall: {recall:.4f}'\n",
    "              f'\\nTest F1 Score: {f1:.4f}'\n",
    "              f'\\nTest Sensitivity: {sensitivity:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data-based k fold CV\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "PROlabels = [np.where(np.array(PROlabels_PhF) >= 1, 1, 0),\n",
    "             np.where(np.array(PROlabels_MF) >= 1, 1, 0),\n",
    "             np.where(np.array(PROlabels_VAS) >= 5, 1, 0)]\n",
    "\n",
    "PROlabels_name = ['PhF', 'MF', 'VAS']\n",
    "\n",
    "# Number of folds for cross-validation\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "all_accuracies = {label: [] for label in PROlabels_name}\n",
    "all_precisions = {label: [] for label in PROlabels_name}\n",
    "all_recalls = {label: [] for label in PROlabels_name}\n",
    "all_f1_scores = {label: [] for label in PROlabels_name}\n",
    "\n",
    "for i, label in enumerate(PROlabels_name):\n",
    "    X = np.array(segments_fulldataset)\n",
    "    y = PROlabels[i]\n",
    "\n",
    "    fold = 1\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        print(f'Fold {fold}/{num_folds}')\n",
    "\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        # Convert data to PyTorch tensors\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "        y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "        X_train_tensor = torch.nan_to_num(X_train_tensor, nan=-10000.0)\n",
    "        X_test_tensor = torch.nan_to_num(X_test_tensor, nan=-10000.0)\n",
    "        # Create DataLoader\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "        batch_size = 64\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Initialize the model, loss function, and optimizer\n",
    "        input_size = 10  \n",
    "        hidden_size = 64  \n",
    "        output_size = 1 \n",
    "        model = AttentionLSTM(input_size, hidden_size, output_size)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        # Train the model\n",
    "        num_epochs = 30\n",
    "        train_losses = []\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            epoch_loss = 0.0\n",
    "            for inputs, labels in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs.squeeze(), labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "            avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "            train_losses.append(avg_epoch_loss)\n",
    "            # print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_epoch_loss:.4f}')\n",
    "        \n",
    "        # torch.save(model, f'models/LSTMWithSelfAttention_{PROlabels_name[i]}_binary.pth')\n",
    "            \n",
    "        # Evaluate the model\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_outputs = []\n",
    "            for inputs, labels in test_loader:\n",
    "                outputs = model(inputs).squeeze()\n",
    "                outputs = np.where(outputs >= 0.5, 1, 0)\n",
    "                test_outputs.extend(outputs.squeeze().tolist())\n",
    "            # Convert outputs to binary (0 or 1)\n",
    "\n",
    "            # Compute evaluation metrics\n",
    "            accuracy = accuracy_score(y_test, test_outputs)\n",
    "            sensitivity = recall_score(y_test, test_outputs, average='weighted')\n",
    "            f1 = f1_score(y_test, test_outputs, average='weighted')\n",
    "            precision = precision_score(y_test, test_outputs, average='weighted', zero_division=1)\n",
    "            recall = recall_score(y_test, test_outputs, average='weighted')\n",
    "            print(f'Test Accuracy: {accuracy:.4f}'\n",
    "                f'\\nTest Precision: {precision:.4f}'\n",
    "                f'\\nTest Recall: {recall:.4f}'\n",
    "                f'\\nTest F1 Score: {f1:.4f}'\n",
    "                f'\\nTest Sensitivity: {sensitivity:.4f}')\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_accuracies[label].append(accuracy)\n",
    "        all_precisions[label].append(precision)\n",
    "        all_recalls[label].append(recall)\n",
    "        all_f1_scores[label].append(f1)\n",
    "\n",
    "        fold += 1\n",
    "\n",
    "# Print average and standard deviation of metrics for each label\n",
    "for label in PROlabels_name:\n",
    "    print(f'\\nLabel: {label}')\n",
    "    print(f'Average Accuracy: {np.mean(all_accuracies[label]):.4f} ± {np.std(all_accuracies[label]):.4f}')\n",
    "    print(f'Average Precision: {np.mean(all_precisions[label]):.4f} ± {np.std(all_precisions[label]):.4f}')\n",
    "    print(f'Average Recall: {np.mean(all_recalls[label]):.4f} ± {np.std(all_recalls[label]):.4f}')\n",
    "    print(f'Average F1 Score: {np.mean(all_f1_scores[label]):.4f} ± {np.std(all_f1_scores[label]):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject-based k fold CV\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "PROlabels = [np.where(np.array(PROlabels_PhF) >= 1, 1, 0),\n",
    "             np.where(np.array(PROlabels_MF) >= 1, 1, 0),\n",
    "             np.where(np.array(PROlabels_VAS) >= 5, 1, 0)]\n",
    "\n",
    "PROlabels_name = ['PhF', 'MF', 'VAS']\n",
    "\n",
    "# Number of folds for cross-validation\n",
    "num_folds = 5\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "all_accuracies = {label: [] for label in PROlabels_name}\n",
    "all_precisions = {label: [] for label in PROlabels_name}\n",
    "all_recalls = {label: [] for label in PROlabels_name}\n",
    "all_f1_scores = {label: [] for label in PROlabels_name}\n",
    "\n",
    "for i, label in enumerate(PROlabels_name):\n",
    "    X = np.array(segments_fulldataset)\n",
    "    y = PROlabels[i]\n",
    "\n",
    "    fold = 1\n",
    "    for group in np.unique(new_array):\n",
    "        print(f'Fold {fold}/{num_folds}')\n",
    "\n",
    "        group_indices = np.where(new_array == group)[0]\n",
    "\n",
    "        # Split data based on group indices\n",
    "        X_test = X[group_indices]\n",
    "        y_test = y[group_indices]\n",
    "\n",
    "        train_indices = np.setdiff1d(np.arange(len(X)), group_indices)\n",
    "        X_train = X[train_indices]\n",
    "        y_train = y[train_indices]\n",
    "\n",
    "\n",
    "        # Convert data to PyTorch tensors\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "        y_test_tensor = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "        X_train_tensor = torch.nan_to_num(X_train_tensor, nan=-10000.0)\n",
    "        X_test_tensor = torch.nan_to_num(X_test_tensor, nan=-10000.0)\n",
    "        # Create DataLoader\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "        batch_size = 64\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Initialize the model, loss function, and optimizer\n",
    "        input_size = 10  \n",
    "        hidden_size = 64 \n",
    "        output_size = 1  \n",
    "        model = AttentionLSTM(input_size, hidden_size, output_size)\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        # Train the model\n",
    "        num_epochs = 30\n",
    "        train_losses = []\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            epoch_loss = 0.0\n",
    "            for inputs, labels in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs.squeeze(), labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "            avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "            train_losses.append(avg_epoch_loss)\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_epoch_loss:.4f}')\n",
    "        \n",
    "        # torch.save(model, f'models/LSTMWithSelfAttention_{PROlabels_name[i]}_binary.pth')\n",
    "        \n",
    "        # Evaluate the model\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_outputs = []\n",
    "            for inputs, labels in test_loader:\n",
    "                outputs = model(inputs).squeeze()\n",
    "                outputs = np.where(outputs >= 0.5, 1, 0)\n",
    "                if outputs.ndim == 0:\n",
    "                    test_outputs.append(outputs)\n",
    "                else:\n",
    "                    test_outputs.extend(outputs.tolist())\n",
    "            # Convert outputs to binary (0 or 1)\n",
    "\n",
    "            # Compute evaluation metrics\n",
    "            accuracy = accuracy_score(y_test, test_outputs)\n",
    "            sensitivity = recall_score(y_test, test_outputs, average='weighted')\n",
    "            f1 = f1_score(y_test, test_outputs, average='weighted')\n",
    "            precision = precision_score(y_test, test_outputs, average='weighted', zero_division=1)\n",
    "            recall = recall_score(y_test, test_outputs, average='weighted')\n",
    "            print(f'Test Accuracy: {accuracy:.4f}'\n",
    "                f'\\nTest Precision: {precision:.4f}'\n",
    "                f'\\nTest Recall: {recall:.4f}'\n",
    "                f'\\nTest F1 Score: {f1:.4f}'\n",
    "                f'\\nTest Sensitivity: {sensitivity:.4f}')\n",
    "\n",
    "        # Append metrics to lists\n",
    "        all_accuracies[label].append(accuracy)\n",
    "        all_precisions[label].append(precision)\n",
    "        all_recalls[label].append(recall)\n",
    "        all_f1_scores[label].append(f1)\n",
    "\n",
    "        fold += 1\n",
    "\n",
    "# Print average and standard deviation of metrics for each label\n",
    "for label in PROlabels_name:\n",
    "    print(f'\\nLabel: {label}')\n",
    "    print(f'Average Accuracy: {np.mean(all_accuracies[label]):.4f} ± {np.std(all_accuracies[label]):.4f}')\n",
    "    print(f'Average Precision: {np.mean(all_precisions[label]):.4f} ± {np.std(all_precisions[label]):.4f}')\n",
    "    print(f'Average Recall: {np.mean(all_recalls[label]):.4f} ± {np.std(all_recalls[label]):.4f}')\n",
    "    print(f'Average F1 Score: {np.mean(all_f1_scores[label]):.4f} ± {np.std(all_f1_scores[label]):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
